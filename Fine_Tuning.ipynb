{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FineTuning.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPZA3x/Rh3kd/4zFed6Vr6C"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ce9bd47287104b05abde6cfa11e1edd1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4d09778de1394bcdbfd79764cc481f95","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f4a9939c5198422c89a4dfb9e185450b","IPY_MODEL_25a5c04bab0a4913af981013f793b67e","IPY_MODEL_3290c85402de4b289c96eb7769d779ad"]}},"4d09778de1394bcdbfd79764cc481f95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f4a9939c5198422c89a4dfb9e185450b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_212582f2b0f94a15ad8fdfc513534b34","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8c9e90e9d498436e9fc0a19adc3b90c1"}},"25a5c04bab0a4913af981013f793b67e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b0703e5e4b9948adbcd73d3b2d270448","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_08cf2442a0d1456da9517dbeedbb535b"}},"3290c85402de4b289c96eb7769d779ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_438fbb1060dd458d9cfd75102039697d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00, 11.67ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_58d869cfaae3499d931c59336500f16c"}},"212582f2b0f94a15ad8fdfc513534b34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8c9e90e9d498436e9fc0a19adc3b90c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b0703e5e4b9948adbcd73d3b2d270448":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"08cf2442a0d1456da9517dbeedbb535b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"438fbb1060dd458d9cfd75102039697d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"58d869cfaae3499d931c59336500f16c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cea86affaf1947ff82a9c89fe6c4c709":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f344d2bb28274f5d8e6168ccc225a93c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aa6d7122358f4f5cb300746ee764995e","IPY_MODEL_b3c7189f35fa47f2a06d732a6f61224b","IPY_MODEL_a18c409536954f098a80c887881e0cf5"]}},"f344d2bb28274f5d8e6168ccc225a93c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa6d7122358f4f5cb300746ee764995e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cf141a7130854bad8b7ce5ec9c064a60","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7b092f71695145f39edef9226a32ebaa"}},"b3c7189f35fa47f2a06d732a6f61224b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d53410d7c996481dae4a983bbdc63c6e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87b78f61e0ac4736b77c789a2dfc6e4b"}},"a18c409536954f098a80c887881e0cf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8be22f0bebe7448591bb92d302c38c7b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00, 28.93ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_37ef3e52482d4082aa49d569df6e87d3"}},"cf141a7130854bad8b7ce5ec9c064a60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7b092f71695145f39edef9226a32ebaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d53410d7c996481dae4a983bbdc63c6e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"87b78f61e0ac4736b77c789a2dfc6e4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8be22f0bebe7448591bb92d302c38c7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"37ef3e52482d4082aa49d569df6e87d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f59640c0284746608b652f54186fb0e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8649a8c83a054daebdfa05a125d996ce","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f1c6c7353b53404f92fc5e5e63238fd0","IPY_MODEL_9f4577d0daca473b89aff3a4085e139b","IPY_MODEL_2978bc661c4f44729d6dc31e1dcbfb0e"]}},"8649a8c83a054daebdfa05a125d996ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1c6c7353b53404f92fc5e5e63238fd0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_550707c7730e437a89e3c85c3f4ba4c2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_37febd5e7b8e4645adbc0fb63a6071e7"}},"9f4577d0daca473b89aff3a4085e139b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5dae04976773446a8fd1ee32dbd7c182","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2283825905,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2283825905,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d4b6776e365f4360858a1ce3abccbb29"}},"2978bc661c4f44729d6dc31e1dcbfb0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_795e25835782446fa6f265e3e1314812","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.28G/2.28G [00:38&lt;00:00, 62.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6612efb2439146b890188254cf4ca1b1"}},"550707c7730e437a89e3c85c3f4ba4c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"37febd5e7b8e4645adbc0fb63a6071e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5dae04976773446a8fd1ee32dbd7c182":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d4b6776e365f4360858a1ce3abccbb29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"795e25835782446fa6f265e3e1314812":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6612efb2439146b890188254cf4ca1b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"IsX9bwh3CtdF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629053165377,"user_tz":-60,"elapsed":12591,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"396a1dd9-1433-4b60-d7ec-c97d83463bcd"},"source":["! pip install datasets transformers rouge-score nltk SentencePiece\n","! pip install --upgrade pyyaml"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting datasets\n","  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n","\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 40 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 264 kB 5.2 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 10.2 MB/s \n","\u001b[?25hCollecting rouge-score\n","  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Collecting SentencePiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 43.0 MB/s \n","\u001b[?25hCollecting fsspec>=2021.05.0\n","  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 70.2 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 53.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting huggingface-hub<0.1.0\n","  Downloading huggingface_hub-0.0.15-py3-none-any.whl (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.3)\n","Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 70.6 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 62.7 MB/s \n","\u001b[?25hCollecting huggingface-hub<0.1.0\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 73.2 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: xxhash, tokenizers, sacremoses, pyyaml, huggingface-hub, fsspec, transformers, SentencePiece, rouge-score, datasets\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed SentencePiece-0.1.96 datasets-1.11.0 fsspec-2021.7.0 huggingface-hub-0.0.12 pyyaml-5.4.1 rouge-score-0.0.4 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2 xxhash-2.0.2\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (5.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GdycxzY0afO8","executionInfo":{"status":"ok","timestamp":1629053182623,"user_tz":-60,"elapsed":4089,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"22639446-f50b-4493-9d10-2ad9e660f893"},"source":["!pip install hf-lfs\n","!git config --global user.email \"jakerutherford@outlook.com\"\n","!git config --global user.name \"JakeMSc\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting hf-lfs\n","  Downloading hf_lfs-0.0.3-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 5.2 MB/s \n","\u001b[?25hInstalling collected packages: hf-lfs\n","Successfully installed hf-lfs-0.0.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eAj40jehaf-0","executionInfo":{"status":"ok","timestamp":1629053202073,"user_tz":-60,"elapsed":12936,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"231289f4-75f6-4b36-f903-cc690115b805"},"source":["!huggingface-cli login"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","        \n","Username: JakeMSc\n","Password: \n","Login successful\n","Your token: hAZfREWUQijkQBHfmbnHEIPIwxTDREXbyBkcGueDblJagPmuXLRagIJaRUiHNaEcQhywCGvKExdpEQRVATeamWsVUOPitqJWcWZygoRNmGHzenCuNuzXqHCPwBjBIAid \n","\n","Your token has been saved to /root/.huggingface/token\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLutZi5De4So","executionInfo":{"status":"ok","timestamp":1629053255763,"user_tz":-60,"elapsed":11039,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"476e9550-b149-40af-c936-0d8c4c739be0"},"source":["model_checkpoint = \"t5-small\"\n","\n","model_name = model_checkpoint.split(\"/\")[-1] + \"-finetuned-ts-and-cs-v2\"\n","!transformers-cli repo create {model_name}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-08-15 18:47:26.384582: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","/usr/local/lib/python3.7/dist-packages/transformers/commands/user.py:269: UserWarning: Managing repositories through transformers-cli is deprecated. Please use `huggingface-cli` instead.\n","  \"Managing repositories through transformers-cli is deprecated. Please use `huggingface-cli` instead.\"\n","\u001b[90mgit version 2.17.1\u001b[0m\n","\u001b[90mgit-lfs/2.13.3 (GitHub; linux amd64; go 1.16.2; git a5e65851)\u001b[0m\n","\n","You are about to create \u001b[1mJakeMSc/t5-base-finetuned-ts-and-cs-v2\u001b[0m\n","Proceed? [Y/n] y\n","\n","Your repo now lives at:\n","  \u001b[1mhttps://huggingface.co/JakeMSc/t5-base-finetuned-ts-and-cs-v2\u001b[0m\n","\n","You can clone it locally with the command below, and commit/push as usual.\n","\n","  git clone https://huggingface.co/JakeMSc/t5-base-finetuned-ts-and-cs-v2\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xuEjx-EvC2kx"},"source":["## Load Data\n","Loading TOSDR.org data from Google Drive"]},{"cell_type":"code","metadata":{"id":"Awi1qgqoCyXc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629053283109,"user_tz":-60,"elapsed":24906,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"0fd0aee6-7d0e-47a7-d62e-040a9a8254bb"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zqFJ8F7j3wRT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629036105524,"user_tz":-60,"elapsed":344,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"dda8af4e-b3a4-4304-8f3f-75c20098acca"},"source":["from datasets import load_dataset\n","\n","dataset_file = 'drive/MyDrive/Colab_Notebooks/train_tosdr_prepared.csv'\n","\n","dataset = load_dataset('csv', data_files=dataset_file, split='train')\n","\n","dataset = dataset.train_test_split(test_size=0.1)\n","\n","train_dataset = dataset['train']\n","val_dataset = dataset['test']"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using custom data configuration default-a4a77547fb39f821\n","Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-a4a77547fb39f821/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"g4zzHOdmHoFN"},"source":["from datasets import load_metric\n","metric = load_metric(\"rouge\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9hoObaG-JcQ2"},"source":["##Tokenize"]},{"cell_type":"code","metadata":{"id":"8c9xR1jHCvMZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629036111351,"user_tz":-60,"elapsed":3444,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"f458d64f-7c8a-490e-8c0d-59a1de4060d9"},"source":["from transformers import AutoTokenizer\n","    \n","tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["loading configuration file https://huggingface.co/google/pegasus-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3fa0446657dd3714a950ba400a3fa72686d0f815da436514e4823a973ef23e20.7a0cb161a6d34c3881891b70d4fa06557175ac7b704a19bf0100fb9c21af9286\n","Model config PegasusConfig {\n","  \"_name_or_path\": \"google/pegasus-large\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"PegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 1,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 0.8,\n","  \"max_length\": 256,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"pegasus\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 8,\n","  \"num_hidden_layers\": 16,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": true,\n","  \"task_specific_params\": {\n","    \"summarization_aeslc\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_arxiv\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_big_patent\": {\n","      \"length_penalty\": 0.7,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_billsum\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_cnn_dailymail\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_gigaword\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 128\n","    },\n","    \"summarization_large\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_multi_news\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_newsroom\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_pubmed\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_reddit_tifu\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_wikihow\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 64,\n","      \"max_position_embeddings\": 512\n","    }\n","  },\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n","loading file https://huggingface.co/google/pegasus-large/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/66f187d645734a6204f3fd24593fbf0d9e36b528dd85b3adae9a566b17b4768f.1acf68c74589da6c7fa3548093824dfc450a54637f4356929bbfea7e294a68f8\n","loading file https://huggingface.co/google/pegasus-large/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/google/pegasus-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/google/pegasus-large/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/fbf9c7cf2d49b24712b53a2760e7c62a2acecd1496908822df00b8ec2683ca6d.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n","loading file https://huggingface.co/google/pegasus-large/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/74256fafbb3cb536e351e6731914d42f732e77d33e537b6c19fb72f4b74f50ea.43f396f0ee3b974f9128267d49f69a26b11f3ed290851ac5788a549cc2979671\n","loading configuration file https://huggingface.co/google/pegasus-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3fa0446657dd3714a950ba400a3fa72686d0f815da436514e4823a973ef23e20.7a0cb161a6d34c3881891b70d4fa06557175ac7b704a19bf0100fb9c21af9286\n","Model config PegasusConfig {\n","  \"_name_or_path\": \"google/pegasus-large\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"PegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 1,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 0.8,\n","  \"max_length\": 256,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"pegasus\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 8,\n","  \"num_hidden_layers\": 16,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": true,\n","  \"task_specific_params\": {\n","    \"summarization_aeslc\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_arxiv\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_big_patent\": {\n","      \"length_penalty\": 0.7,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_billsum\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_cnn_dailymail\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_gigaword\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 128\n","    },\n","    \"summarization_large\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_multi_news\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_newsroom\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_pubmed\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_reddit_tifu\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_wikihow\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 64,\n","      \"max_position_embeddings\": 512\n","    }\n","  },\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n","loading configuration file https://huggingface.co/google/pegasus-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3fa0446657dd3714a950ba400a3fa72686d0f815da436514e4823a973ef23e20.7a0cb161a6d34c3881891b70d4fa06557175ac7b704a19bf0100fb9c21af9286\n","Model config PegasusConfig {\n","  \"_name_or_path\": \"google/pegasus-large\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"PegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 1,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 0.8,\n","  \"max_length\": 256,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"pegasus\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 8,\n","  \"num_hidden_layers\": 16,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": true,\n","  \"task_specific_params\": {\n","    \"summarization_aeslc\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_arxiv\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_big_patent\": {\n","      \"length_penalty\": 0.7,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_billsum\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_cnn_dailymail\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_gigaword\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 128\n","    },\n","    \"summarization_large\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_multi_news\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_newsroom\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_pubmed\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_reddit_tifu\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_wikihow\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 64,\n","      \"max_position_embeddings\": 512\n","    }\n","  },\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6c94MUk_iKhW"},"source":["max_input_length = 512\n","max_target_length = 128\n","\n","if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-large\", \"t5-3b\", \"t5-11b\"]:\n","    prefix = \"summarize: \"\n","else:\n","    prefix = \"\"\n","\n","def preprocess_function(examples):\n","    inputs = [prefix + doc for doc in examples[\"document\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7usoXyX9l5-z","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["ce9bd47287104b05abde6cfa11e1edd1","4d09778de1394bcdbfd79764cc481f95","f4a9939c5198422c89a4dfb9e185450b","25a5c04bab0a4913af981013f793b67e","3290c85402de4b289c96eb7769d779ad","212582f2b0f94a15ad8fdfc513534b34","8c9e90e9d498436e9fc0a19adc3b90c1","b0703e5e4b9948adbcd73d3b2d270448","08cf2442a0d1456da9517dbeedbb535b","438fbb1060dd458d9cfd75102039697d","58d869cfaae3499d931c59336500f16c","cea86affaf1947ff82a9c89fe6c4c709","f344d2bb28274f5d8e6168ccc225a93c","aa6d7122358f4f5cb300746ee764995e","b3c7189f35fa47f2a06d732a6f61224b","a18c409536954f098a80c887881e0cf5","cf141a7130854bad8b7ce5ec9c064a60","7b092f71695145f39edef9226a32ebaa","d53410d7c996481dae4a983bbdc63c6e","87b78f61e0ac4736b77c789a2dfc6e4b","8be22f0bebe7448591bb92d302c38c7b","37ef3e52482d4082aa49d569df6e87d3"]},"executionInfo":{"status":"ok","timestamp":1629036115770,"user_tz":-60,"elapsed":229,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"1f2ced62-2872-40e9-f024-c28e01dbacb9"},"source":["tokenized_datasets = dataset.map(preprocess_function, batched=True)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce9bd47287104b05abde6cfa11e1edd1","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cea86affaf1947ff82a9c89fe6c4c709","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"sNKR27-R1Wk2","executionInfo":{"status":"ok","timestamp":1629036118500,"user_tz":-60,"elapsed":304,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"32208c31-6deb-4c37-e200-81e6ea78d138"},"source":["tokenized_datasets['train']['document'][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'cookies are small data files that are commonly stored on your device when you browse and use websites and online services. they are widely used to make websites work or to work more efficiently as well as to provide reporting information and assist with service or advertising personalization. cookies are not the only types of technology that enable this functionality. we also use other similar types of technologies. see below for more information and examples. what are advertising identifiers. advertising identifiers are similar to cookies and are found on many mobile devices and tablets for example the identifier for advertisers or idfa on apple ios devices and the google advertising id on android devices and certain streaming media devices. like cookies advertising identifiers are used to make online advertising more relevant. why does netflix use cookies and advertising identifiers. essential cookies these cookies are strictly necessary to provide our website or online service. for example we and our service providers may use these cookies to authenticate and identify our members when they use our websites and applications so we can provide our service to them. they also help us to enforce our terms of use prevent fraud and maintain the security of our service. performance and functionality cookies these cookies are not essential but help us to personalize and enhance your online experience with netflix. for example they help us to remember your preferences and prevent you from needing to re enter information you previously provided for example during member sign up. we also use these cookies to collect information such as popular pages conversion rates viewing patterns click through and other information about our visitors use of the netflix service so that we can enhance and personalize our website and service and conduct market research. deletion of these types of cookies may result in limited functionality of our service. advertising cookies and advertising identifiers these cookies and advertising identifiers use information about your use of this and other websites and apps your response to ads and emails and to deliver ads that are more relevant to you. these types of ads are called interest based advertising. many of the advertising cookies associated with our service belong to our service providers. how can i exercise choice regarding cookies and advertising identifiers. for more information about cookies set through our website as well as other types of online tracking including the collection of information by third parties about your online activities over time and across third party web sites or online services for online interest based advertising and to exercise choices regarding them click here. to opt out of interest based ads from netflix in connection with an advertising identifier on a mobile device tablet or streaming media devices please configure the appropriate setting on your device usually found under privacy or ads in your device s settings. you may still see netflix ads on your device but they will not be tailored to your likely interests. netflix supports the following self regulatory programs which provide additional privacy choices for interest based advertising in the us digital advertising alliance daa in europe european interactive digital advertising alliance edaa in canada ad choices digital advertising alliance of canada daac choix de pub l alliance de la publicité numérique du canada daac at this time we do not respond to web browser do not track signals. how does netflix use web beacons and other technologies. web beacons also known as clear gifs or pixel tags often work in conjunction with cookies. we and our service providers may use them for similar purposes as cookies such as to understand and enhance the use of our service improve site performance monitor visitor traffic and actions on our site and understand interactions with our marketing including email and online ads on third party sites. because web beacons often work in conjunction with cookies in many cases declining cookies will impair the effectiveness of web beacons associated with those cookies. we use other technologies that are similar to cookies such as browser storage and plugins e g html5 indexeddb and websql. like cookies some of these technologies may store small amounts of data on your device. we may use these and various other technologies for similar purposes as cookies such as to enforce our terms prevent fraud and analyze the use of our service. there are a number of ways to exercise choice regarding these technologies. for example many popular browsers provide the ability to clear browser storage commonly in the settings or preferences area. see your browser s help function or support area to learn more. other technologies such as silverlight storage may be cleared from within the application.'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"5DNUi0HJeKpf"},"source":["## Fine-tuning"]},{"cell_type":"code","metadata":{"id":"_VoyalEReNpf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629036164367,"user_tz":-60,"elapsed":44141,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"61e0faba-cbe5-497e-880f-4783d39fe15f"},"source":["from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","import torch \n","\n","torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, use_auth_token=True).to(torch_device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["loading configuration file https://huggingface.co/google/pegasus-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3fa0446657dd3714a950ba400a3fa72686d0f815da436514e4823a973ef23e20.7a0cb161a6d34c3881891b70d4fa06557175ac7b704a19bf0100fb9c21af9286\n","Model config PegasusConfig {\n","  \"_name_or_path\": \"google/pegasus-large\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"PegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 1,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 0.8,\n","  \"max_length\": 256,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"pegasus\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 8,\n","  \"num_hidden_layers\": 16,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": true,\n","  \"task_specific_params\": {\n","    \"summarization_aeslc\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_arxiv\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_big_patent\": {\n","      \"length_penalty\": 0.7,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_billsum\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_cnn_dailymail\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_gigaword\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 128\n","    },\n","    \"summarization_large\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_multi_news\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_newsroom\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_pubmed\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_reddit_tifu\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_wikihow\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 64,\n","      \"max_position_embeddings\": 512\n","    }\n","  },\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n","loading weights file https://huggingface.co/google/pegasus-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/ef3a8274e003ba4d3ae63f2728378e73affec0029e797c0bbb80be8856130c4f.a99cb24bd92c7087e95d96a1c3eb660b51e498705f8bd068a58c69c20616f514\n","All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n","\n","All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at google/pegasus-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"U-V1ob9FFzxy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629036164368,"user_tz":-60,"elapsed":20,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"6a828559-434b-4e80-f1e8-c57705ea7548"},"source":["batch_size = 1\n","args = Seq2SeqTrainingArguments(\n","    output_dir='./results',\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    eval_accumulation_steps=1,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=10,\n","    predict_with_generate=True,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    adafactor=True,\n","    push_to_hub=True,\n","    push_to_hub_model_id=model_name,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-vi4o1t7GGbj"},"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vbahU-bGQXp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629036164369,"user_tz":-60,"elapsed":15,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"d5c6ff1b-8388-4132-da77-f1d77300d59b"},"source":["import nltk\n","import numpy as np\n","\n","nltk.download('punkt')\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    \n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    \n","    # Rouge expects a newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","    \n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    # Extract a few results\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","    \n","    # Add mean generated length\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    \n","    return {k: round(v, 4) for k, v in result.items()}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wcMi8duwGREI"},"source":["trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"uGIRte3lKZok","executionInfo":{"status":"ok","timestamp":1629037562530,"user_tz":-60,"elapsed":1220590,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"c03fbd6e-fc05-42ef-d81b-a1a6493b70e6"},"source":["trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The following columns in the training set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: Unnamed: 0, document, url, summary.\n","***** Running training *****\n","  Num examples = 291\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 1\n","  Total train batch size (w. parallel, distributed & accumulation) = 1\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2910\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2910' max='2910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2910/2910 20:19, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.261700</td>\n","      <td>2.136362</td>\n","      <td>26.216300</td>\n","      <td>8.457000</td>\n","      <td>21.851500</td>\n","      <td>21.777000</td>\n","      <td>32.575800</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.443900</td>\n","      <td>1.876113</td>\n","      <td>27.956200</td>\n","      <td>10.940300</td>\n","      <td>24.911700</td>\n","      <td>24.870600</td>\n","      <td>31.636400</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.043000</td>\n","      <td>1.727877</td>\n","      <td>32.238700</td>\n","      <td>14.504700</td>\n","      <td>27.846500</td>\n","      <td>27.941400</td>\n","      <td>27.363600</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.348000</td>\n","      <td>1.678856</td>\n","      <td>32.551600</td>\n","      <td>15.971000</td>\n","      <td>27.586500</td>\n","      <td>27.864700</td>\n","      <td>27.545500</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.154200</td>\n","      <td>1.623587</td>\n","      <td>33.370800</td>\n","      <td>16.769400</td>\n","      <td>28.323200</td>\n","      <td>28.220300</td>\n","      <td>22.060600</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.401000</td>\n","      <td>1.585874</td>\n","      <td>33.182900</td>\n","      <td>16.953000</td>\n","      <td>28.439800</td>\n","      <td>28.101200</td>\n","      <td>19.969700</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.301700</td>\n","      <td>1.604203</td>\n","      <td>40.062600</td>\n","      <td>23.505600</td>\n","      <td>35.892100</td>\n","      <td>35.571700</td>\n","      <td>17.909100</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.111600</td>\n","      <td>1.575186</td>\n","      <td>40.429000</td>\n","      <td>24.604800</td>\n","      <td>36.533500</td>\n","      <td>36.172300</td>\n","      <td>19.454500</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.816600</td>\n","      <td>1.588958</td>\n","      <td>38.484600</td>\n","      <td>22.638400</td>\n","      <td>34.185500</td>\n","      <td>34.417300</td>\n","      <td>19.484800</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.263000</td>\n","      <td>1.593920</td>\n","      <td>38.669000</td>\n","      <td>22.776200</td>\n","      <td>34.487400</td>\n","      <td>34.670900</td>\n","      <td>18.697000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: Unnamed: 0, document, url, summary.\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 1\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: Unnamed: 0, document, url, summary.\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 1\n","The following columns in the evaluation set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: Unnamed: 0, document, url, summary.\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 1\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: Unnamed: 0, document, url, summary.\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 1\n","The following columns in the evaluation set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: Unnamed: 0, document, url, summary.\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 1\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: Unnamed: 0, document, url, summary.\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 1\n","Saving model checkpoint to ./results/checkpoint-2000\n","Configuration saved in ./results/checkpoint-2000/config.json\n","Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: Unnamed: 0, document, url, summary.\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 1\n","The following columns in the evaluation set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: Unnamed: 0, document, url, summary.\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 1\n","Saving model checkpoint to ./results/checkpoint-2500\n","Configuration saved in ./results/checkpoint-2500/config.json\n","Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: Unnamed: 0, document, url, summary.\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 1\n","The following columns in the evaluation set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: Unnamed: 0, document, url, summary.\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 1\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2910, training_loss=1.5935436279912993, metrics={'train_runtime': 1220.2479, 'train_samples_per_second': 2.385, 'train_steps_per_second': 2.385, 'total_flos': 772113425448960.0, 'train_loss': 1.5935436279912993, 'epoch': 10.0})"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"_c-eFImAAF10"},"source":["## Save model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120},"id":"TOTqxsckAr07","executionInfo":{"status":"ok","timestamp":1629034791648,"user_tz":-60,"elapsed":114911,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"3f38d01b-f7fc-4209-aa88-d310327a65e8"},"source":["trainer.push_to_hub()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model checkpoint to ./results\n","Configuration saved in ./results/config.json\n","Model weights saved in ./results/pytorch_model.bin\n","tokenizer config file saved in ./results/tokenizer_config.json\n","Special tokens file saved in ./results/special_tokens_map.json\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'https://huggingface.co/JakeMSc/pegasus-large-finetuned-ts-and-cs-v2/commit/ad17d496d316adb9cd305dda4e9fb7e25a17fa34'"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"7_1wSIqen-HK"},"source":["## Testing model"]},{"cell_type":"code","metadata":{"id":"xFjHqB8Yn9fE","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f59640c0284746608b652f54186fb0e4","8649a8c83a054daebdfa05a125d996ce","f1c6c7353b53404f92fc5e5e63238fd0","9f4577d0daca473b89aff3a4085e139b","2978bc661c4f44729d6dc31e1dcbfb0e","550707c7730e437a89e3c85c3f4ba4c2","37febd5e7b8e4645adbc0fb63a6071e7","5dae04976773446a8fd1ee32dbd7c182","d4b6776e365f4360858a1ce3abccbb29","795e25835782446fa6f265e3e1314812","6612efb2439146b890188254cf4ca1b1"]},"executionInfo":{"status":"ok","timestamp":1629017969014,"user_tz":-60,"elapsed":56929,"user":{"displayName":"Jake Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXg39iHaD5A3BraJJ4_Q0pLnXwY6rfEiIHPfBpAQ=s64","userId":"04903468185099854714"}},"outputId":"ace53fc1-bf50-4d3b-edd2-cb167c501b88"},"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","import torch\n","\n","torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","model_checkpoint = \"google/pegasus-large\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","\n","my_model = 'JakeMSc/pegasus-large-legal-dapt-finetuned-ts-and-cs'\n","\n","#tokenizer = AutoTokenizer.from_pretrained(my_model)  \n","model = AutoModelForSeq2SeqLM.from_pretrained(my_model, use_auth_token=True).to(torch_device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["loading configuration file https://huggingface.co/google/pegasus-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3fa0446657dd3714a950ba400a3fa72686d0f815da436514e4823a973ef23e20.7a0cb161a6d34c3881891b70d4fa06557175ac7b704a19bf0100fb9c21af9286\n","Model config PegasusConfig {\n","  \"_name_or_path\": \"google/pegasus-large\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"PegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 1,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 0.8,\n","  \"max_length\": 256,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"pegasus\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 8,\n","  \"num_hidden_layers\": 16,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": true,\n","  \"task_specific_params\": {\n","    \"summarization_aeslc\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_arxiv\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_big_patent\": {\n","      \"length_penalty\": 0.7,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_billsum\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_cnn_dailymail\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_gigaword\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 128\n","    },\n","    \"summarization_large\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_multi_news\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_newsroom\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_pubmed\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_reddit_tifu\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_wikihow\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 64,\n","      \"max_position_embeddings\": 512\n","    }\n","  },\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n","loading file https://huggingface.co/google/pegasus-large/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/66f187d645734a6204f3fd24593fbf0d9e36b528dd85b3adae9a566b17b4768f.1acf68c74589da6c7fa3548093824dfc450a54637f4356929bbfea7e294a68f8\n","loading file https://huggingface.co/google/pegasus-large/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/google/pegasus-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/google/pegasus-large/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/fbf9c7cf2d49b24712b53a2760e7c62a2acecd1496908822df00b8ec2683ca6d.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n","loading file https://huggingface.co/google/pegasus-large/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/74256fafbb3cb536e351e6731914d42f732e77d33e537b6c19fb72f4b74f50ea.43f396f0ee3b974f9128267d49f69a26b11f3ed290851ac5788a549cc2979671\n","loading configuration file https://huggingface.co/google/pegasus-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3fa0446657dd3714a950ba400a3fa72686d0f815da436514e4823a973ef23e20.7a0cb161a6d34c3881891b70d4fa06557175ac7b704a19bf0100fb9c21af9286\n","Model config PegasusConfig {\n","  \"_name_or_path\": \"google/pegasus-large\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"PegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 1,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 0.8,\n","  \"max_length\": 256,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"pegasus\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 8,\n","  \"num_hidden_layers\": 16,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": true,\n","  \"task_specific_params\": {\n","    \"summarization_aeslc\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_arxiv\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_big_patent\": {\n","      \"length_penalty\": 0.7,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_billsum\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_cnn_dailymail\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_gigaword\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 128\n","    },\n","    \"summarization_large\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_multi_news\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_newsroom\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_pubmed\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_reddit_tifu\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_wikihow\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 64,\n","      \"max_position_embeddings\": 512\n","    }\n","  },\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n","loading configuration file https://huggingface.co/google/pegasus-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3fa0446657dd3714a950ba400a3fa72686d0f815da436514e4823a973ef23e20.7a0cb161a6d34c3881891b70d4fa06557175ac7b704a19bf0100fb9c21af9286\n","Model config PegasusConfig {\n","  \"_name_or_path\": \"google/pegasus-large\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"PegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 1,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 0.8,\n","  \"max_length\": 256,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"pegasus\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 8,\n","  \"num_hidden_layers\": 16,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": true,\n","  \"task_specific_params\": {\n","    \"summarization_aeslc\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_arxiv\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_big_patent\": {\n","      \"length_penalty\": 0.7,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_billsum\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_cnn_dailymail\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_gigaword\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 128\n","    },\n","    \"summarization_large\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_multi_news\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_newsroom\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_pubmed\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_reddit_tifu\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_wikihow\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 64,\n","      \"max_position_embeddings\": 512\n","    }\n","  },\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n","loading configuration file https://huggingface.co/JakeMSc/pegasus-large-legal-dapt-finetuned-ts-and-cs/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a01ae6529a6d058b865aa76d019c2e6a02b5d4c167665c58a66d2ab7d72593a0.f05e2037b4895551eed82607f7ef93390896215855fc86221ae5ca612b25bfb3\n","Model config PegasusConfig {\n","  \"_name_or_path\": \"JakeMSc/pegasus-large-legal\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"PegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 1,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 0.8,\n","  \"max_length\": 256,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"pegasus\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 8,\n","  \"num_hidden_layers\": 16,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": true,\n","  \"task_specific_params\": {\n","    \"summarization_aeslc\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_arxiv\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_big_patent\": {\n","      \"length_penalty\": 0.7,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_billsum\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_cnn_dailymail\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_gigaword\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 32,\n","      \"max_position_embeddings\": 128\n","    },\n","    \"summarization_large\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_multi_news\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_newsroom\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_pubmed\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 1024\n","    },\n","    \"summarization_reddit_tifu\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 128,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_wikihow\": {\n","      \"length_penalty\": 0.6,\n","      \"max_length\": 256,\n","      \"max_position_embeddings\": 512\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 0.8,\n","      \"max_length\": 64,\n","      \"max_position_embeddings\": 512\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n","https://huggingface.co/JakeMSc/pegasus-large-legal-dapt-finetuned-ts-and-cs/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpnb6v2f4u\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f59640c0284746608b652f54186fb0e4","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/JakeMSc/pegasus-large-legal-dapt-finetuned-ts-and-cs/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/543b81b673aa12425582b9bbc273c4951adbc85ef6dd9b20fc24956e70e17a86.d8c50a847bc0bb42d1045118a440bb3fccaba0511d796ce881a0e1d53b59e98a\n","creating metadata file for /root/.cache/huggingface/transformers/543b81b673aa12425582b9bbc273c4951adbc85ef6dd9b20fc24956e70e17a86.d8c50a847bc0bb42d1045118a440bb3fccaba0511d796ce881a0e1d53b59e98a\n","loading weights file https://huggingface.co/JakeMSc/pegasus-large-legal-dapt-finetuned-ts-and-cs/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/543b81b673aa12425582b9bbc273c4951adbc85ef6dd9b20fc24956e70e17a86.d8c50a847bc0bb42d1045118a440bb3fccaba0511d796ce881a0e1d53b59e98a\n","All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n","\n","All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at JakeMSc/pegasus-large-legal-dapt-finetuned-ts-and-cs.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"oPVjRRmso_NQ"},"source":["print(\"input:\")\n","input_text = input()\n","\n","with torch.no_grad():\n","    tokenized_text = tokenizer(input_text, truncation=True, padding=True, return_tensors='pt')\n","\n","    source_ids = tokenized_text['input_ids'].to(torch_device, dtype = torch.long)\n","    source_mask = tokenized_text['attention_mask'].to(torch_device, dtype = torch.long)\n","\n","    generated_ids = model.generate(\n","        input_ids=source_ids,\n","        attention_mask=source_mask,\n","        max_length=250,\n","        num_beams=9,\n","        length_penalty=5.0, \n","        early_stopping=True,\n","        no_repeat_ngram_size=2\n","    )\n","\n","    pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","\n","print(\"\\noutput:\\n\" + pred)"],"execution_count":null,"outputs":[]}]}